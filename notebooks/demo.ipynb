{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b26e82",
   "metadata": {},
   "source": [
    "# üîê Data Anonymization with LLMs - End-to-End Demo\n",
    "\n",
    "This notebook demonstrates the modular framework for text anonymization.\n",
    "\n",
    "**Available methods:**\n",
    "- **EDA** (Easy Data Augmentation): Baseline techniques using WordNet\n",
    "- **KNEO** (Knowledge-based Neighbor Operation): Embeddings (GloVe/fastText)\n",
    "- **LLM**: Language models via Ollama (gemma2, llama3.2, mistral, etc.)\n",
    "\n",
    "**To change configuration:**\n",
    "Edit the `configs/config.yaml` file to change models, datasets, and parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd8172",
   "metadata": {},
   "source": [
    "## 1. üöÄ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d12c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (first time only)\n",
    "# !pip install -r ../requirements.txt\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167443f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "# Import framework modules\n",
    "from eda_anonymizer import EDAAnonymizer\n",
    "from kneo_anonymizer import KNEOAnonymizer\n",
    "from llm_anonymizer import OllamaAnonymizer, PROMPT_TEMPLATES\n",
    "from metrics import AnonymizationMetrics\n",
    "from utils import (\n",
    "    load_config, \n",
    "    load_all_datasets, \n",
    "    set_all_seeds,\n",
    "    create_output_dir,\n",
    "    save_anonymized_dataset,\n",
    "    save_metrics,\n",
    "    print_comparison_table\n",
    ")\n",
    "\n",
    "# Import visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup visualization\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc5369",
   "metadata": {},
   "source": [
    "from src.utils import load_config, load_all_datasets\n",
    "from src.eda_anonymizer import EDAAnonymizer\n",
    "from src.kneo_anonymizer import KNEOAnonymizer\n",
    "from src.llm_anonymizer import OllamaAnonymizer\n",
    "from src.metrics import AnonymizationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27199532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from YAML file\n",
    "config = load_config('../configs/config.yaml')\n",
    "\n",
    "# Display main configuration\n",
    "print(\"\\nüìã CURRENT CONFIGURATION:\")\n",
    "print(f\"   EDA alphas: SR={config['eda']['alpha_sr']}, RI={config['eda']['alpha_ri']}, RS={config['eda']['alpha_rs']}, RD={config['eda']['alpha_rd']}\")\n",
    "print(f\"   KNEO: model={config['kneo']['embedding_model']}, k={config['kneo']['k']}\")\n",
    "print(f\"   LLM: model={config['llm']['model_name']}, temp={config['llm']['temperature']}\")\n",
    "print(f\"   Metrics: SBERT={config['metrics']['sbert_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b034c721",
   "metadata": {},
   "source": [
    "### 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample size for quick testing (None = full dataset)\n",
    "SAMPLE_SIZES = {\n",
    "    'train': 100,       # Change to None to use all data\n",
    "    'validation': 50,\n",
    "    'test': None\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "datasets = load_all_datasets(\n",
    "    config, \n",
    "    base_dir='../data',\n",
    "    sample_sizes=SAMPLE_SIZES\n",
    ")\n",
    "\n",
    "# Extract for convenience\n",
    "if 'train' in datasets:\n",
    "    train_texts, train_labels = datasets['train']\n",
    "    print(f\"\\nüìä Training set: {len(train_texts)} samples\")\n",
    "\n",
    "if 'validation' in datasets:\n",
    "    val_texts, val_labels = datasets['validation']\n",
    "    print(f\"üìä Validation set: {len(val_texts)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31176ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some examples\n",
    "print(\"\\nüîç Examples from dataset:\\n\")\n",
    "for i in range(min(5, len(val_texts))):\n",
    "    print(f\"[{val_labels[i]}] {val_texts[i][:100]}...\" if len(val_texts[i]) > 100 else f\"[{val_labels[i]}] {val_texts[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4148f4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. üìù Metodo 1: Easy Data Augmentation (EDA)\n",
    "\n",
    "EDA applica 4 tecniche di augmentation:\n",
    "- **SR** (Synonym Replacement): Sostituisce parole con sinonimi da WordNet\n",
    "- **RI** (Random Insertion): Inserisce sinonimi casuali\n",
    "- **RS** (Random Swap): Scambia posizioni di parole\n",
    "- **RD** (Random Deletion): Elimina parole casuali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EDA Anonymizer\n",
    "eda = EDAAnonymizer()\n",
    "\n",
    "# Apply anonymization\n",
    "print(\"üîÑ Applying EDA...\")\n",
    "anonymized_eda = eda.anonymize_batch(\n",
    "    val_texts,\n",
    "    alpha_sr=config['eda']['alpha_sr'],\n",
    "    alpha_ri=config['eda']['alpha_ri'],\n",
    "    alpha_rs=config['eda']['alpha_rs'],\n",
    "    alpha_rd=config['eda']['alpha_rd'],\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ EDA completed: {len(anonymized_eda)} sentences anonymized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22deb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples\n",
    "print(\"üìù EDA anonymization examples:\\n\")\n",
    "print(\"-\" * 80)\n",
    "for i in range(min(5, len(val_texts))):\n",
    "    print(f\"\\nüîπ ORIGINAL:  {val_texts[i]}\")\n",
    "    print(f\"üî∏ EDA:       {anonymized_eda[i]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5981cde5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. üß† Metodo 2: KNEO (Knowledge-based Neighbor Operation)\n",
    "\n",
    "KNEO usa embeddings pre-addestrati per sostituire parole con vicini semantici.\n",
    "\n",
    "**Modelli disponibili:**\n",
    "- `glove-wiki-gigaword-50/100/200/300` - GloVe embeddings\n",
    "- `fasttext-wiki-news-subwords-300` - FastText (migliore per testi rumorosi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KNEO Anonymizer\n",
    "kneo = KNEOAnonymizer(\n",
    "    embedding_model=config['kneo']['embedding_model'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply anonymization\n",
    "print(\"\\nüîÑ Applying KNEO...\")\n",
    "anonymized_kneo = kneo.anonymize_batch(\n",
    "    val_texts,\n",
    "    k=config['kneo']['k'],\n",
    "    strategy=config['kneo']['strategy'],\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ KNEO completed: {len(anonymized_kneo)} sentences anonymized\")\n",
    "\n",
    "# Cache statistics\n",
    "cache_stats = kneo.get_cache_stats()\n",
    "print(f\"üíæ Cache: {cache_stats['cache_size']} unique words processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ff94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples\n",
    "print(\"üìù KNEO anonymization examples:\\n\")\n",
    "print(\"-\" * 80)\n",
    "for i in range(min(5, len(val_texts))):\n",
    "    print(f\"\\nüîπ ORIGINAL:  {val_texts[i]}\")\n",
    "    print(f\"üî∏ KNEO:      {anonymized_kneo[i]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac5ac5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ü§ñ Method 3: LLM with Ollama\n",
    "\n",
    "Use local LLM models via Ollama for more sophisticated anonymization.\n",
    "\n",
    "### Ollama Setup (if not already installed)\n",
    "\n",
    "```bash\n",
    "# Run the setup script\n",
    "bash scripts/setup_ollama.sh\n",
    "\n",
    "# Or manually:\n",
    "# macOS: brew install ollama\n",
    "# Linux: curl -fsSL https://ollama.ai/install.sh | sh\n",
    "\n",
    "# Start the server\n",
    "ollama serve\n",
    "\n",
    "# Download a model (in another terminal)\n",
    "ollama pull gemma2:2b    # Small and fast\n",
    "ollama pull llama3.2     # Meta's latest\n",
    "ollama pull mistral      # Good balance\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try connecting to Ollama\n",
    "try:\n",
    "    llm = OllamaAnonymizer(\n",
    "        model_name=config['llm']['model_name'],\n",
    "        base_url=config['llm']['base_url'],\n",
    "        temperature=config['llm']['temperature'],\n",
    "        max_tokens=config['llm']['max_tokens'],\n",
    "        prompt_style=\"paraphrase\",\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    OLLAMA_AVAILABLE = True\n",
    "    print(\"\\n‚úÖ Ollama connected and ready!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    OLLAMA_AVAILABLE = False\n",
    "    print(f\"\\n‚ö†Ô∏è  Ollama not available: {e}\")\n",
    "    print(\"   Skip this section if you don't have Ollama installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb72c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LLM (only if available)\n",
    "if OLLAMA_AVAILABLE:\n",
    "    # Use a smaller subset for LLM (it's slower)\n",
    "    llm_sample_size = min(20, len(val_texts))\n",
    "    llm_texts = val_texts[:llm_sample_size]\n",
    "    llm_labels = val_labels[:llm_sample_size]\n",
    "    \n",
    "    print(f\"\\nüîÑ Applying LLM ({llm_sample_size} samples)...\")\n",
    "    \n",
    "    anonymized_llm = llm.anonymize_batch(\n",
    "        llm_texts,\n",
    "        labels=llm_labels,\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ LLM completed: {len(anonymized_llm)} sentences anonymized\")\n",
    "else:\n",
    "    anonymized_llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc51731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show LLM examples\n",
    "if anonymized_llm:\n",
    "    print(\"üìù LLM anonymization examples:\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    for i in range(min(5, len(anonymized_llm))):\n",
    "        print(f\"\\nüîπ ORIGINAL:  {llm_texts[i]}\")\n",
    "        print(f\"üî∏ LLM:       {anonymized_llm[i]}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1bbe2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. üìä Evaluation with Metrics\n",
    "\n",
    "Evaluate results with 4 metrics:\n",
    "\n",
    "| Metric | Category | Goal |\n",
    "|---------|-----------|----------|\n",
    "| Levenshtein Ratio | Irreversibility | ‚Üì Lower = better |\n",
    "| Jaccard Similarity | Irreversibility | ‚Üì Lower = better |\n",
    "| Cosine Similarity | Semantic Utility | ‚Üë Higher = better |\n",
    "| NER Score | Anonymization | ‚Üë Higher = better |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics module\n",
    "metrics = AnonymizationMetrics(\n",
    "    sbert_model=config['metrics']['sbert_model'],\n",
    "    spacy_model=config['metrics']['spacy_model'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf483b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate EDA\n",
    "print(\"\\nüìä Evaluating EDA...\")\n",
    "eda_results = metrics.evaluate_all(val_texts, anonymized_eda, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate KNEO\n",
    "print(\"\\nüìä Evaluating KNEO...\")\n",
    "kneo_results = metrics.evaluate_all(val_texts, anonymized_kneo, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LLM (if available)\n",
    "if anonymized_llm:\n",
    "    print(\"\\nüìä Evaluating LLM...\")\n",
    "    llm_results = metrics.evaluate_all(llm_texts, anonymized_llm, show_progress=True)\n",
    "else:\n",
    "    llm_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36017b5",
   "metadata": {},
   "source": [
    "### 5.1 Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "all_results = {\n",
    "    'EDA': eda_results,\n",
    "    'KNEO': kneo_results\n",
    "}\n",
    "\n",
    "if llm_results:\n",
    "    all_results['LLM'] = llm_results\n",
    "\n",
    "# Print comparison table\n",
    "print_comparison_table(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a830721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for analysis\n",
    "df_results = pd.DataFrame(all_results).T\n",
    "df_results.index.name = 'Method'\n",
    "df_results = df_results.round(4)\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9da938",
   "metadata": {},
   "source": [
    "### 5.2 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9389909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart for comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics_names = ['levenshtein_ratio', 'jaccard_similarity', 'cosine_similarity', 'ner_score']\n",
    "metric_labels = ['Levenshtein Ratio ‚Üì', 'Jaccard Similarity ‚Üì', 'Cosine Similarity ‚Üë', 'NER Score ‚Üë']\n",
    "colors = ['#e74c3c', '#e74c3c', '#27ae60', '#27ae60']\n",
    "\n",
    "methods = list(all_results.keys())\n",
    "\n",
    "for idx, (metric, label, color) in enumerate(zip(metrics_names, metric_labels, colors)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    values = [all_results[m][metric] for m in methods]\n",
    "    \n",
    "    bars = ax.bar(methods, values, color=color, alpha=0.8, edgecolor='black')\n",
    "    ax.set_title(label, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    for bar, val in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.suptitle('Anonymization Metrics Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ca29f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. üíæ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = create_output_dir(config)\n",
    "print(f\"üìÅ Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87358c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save anonymized datasets\n",
    "if config['output']['save_anonymized']:\n",
    "    save_anonymized_dataset(anonymized_eda, val_labels, output_dir, 'eda')\n",
    "    save_anonymized_dataset(anonymized_kneo, val_labels, output_dir, 'kneo')\n",
    "    \n",
    "    if anonymized_llm:\n",
    "        save_anonymized_dataset(anonymized_llm, llm_labels, output_dir, 'llm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abdad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "if config['output']['save_metrics']:\n",
    "    save_metrics(all_results, output_dir, 'comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe5bbfb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. üî¨ Advanced Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624246b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different alpha configurations for EDA\n",
    "alpha_configs = [\n",
    "    {'name': 'Light', 'sr': 0.1, 'ri': 0.1, 'rs': 0.1, 'rd': 0.1},\n",
    "    {'name': 'Medium', 'sr': 0.3, 'ri': 0.3, 'rs': 0.3, 'rd': 0.3},\n",
    "    {'name': 'Aggressive', 'sr': 0.5, 'ri': 0.5, 'rs': 0.5, 'rd': 0.5},\n",
    "]\n",
    "\n",
    "eda_comparison = {}\n",
    "test_texts = val_texts[:30]\n",
    "\n",
    "for cfg in alpha_configs:\n",
    "    print(f\"\\nüîÑ Testing EDA {cfg['name']}...\")\n",
    "    anon = eda.anonymize_batch(\n",
    "        test_texts, \n",
    "        alpha_sr=cfg['sr'], alpha_ri=cfg['ri'], \n",
    "        alpha_rs=cfg['rs'], alpha_rd=cfg['rd'],\n",
    "        show_progress=False\n",
    "    )\n",
    "    results = metrics.evaluate_all(test_texts, anon, show_progress=False)\n",
    "    eda_comparison[f\"EDA-{cfg['name']}\"] = results\n",
    "    print(f\"   Cosine: {results['cosine_similarity']:.3f}, NER: {results['ner_score']:.3f}\")\n",
    "\n",
    "print_comparison_table(eda_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593e0fd2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. üìù Conclusions\n",
    "\n",
    "### Summary of methods:\n",
    "\n",
    "| Method | Pros | Cons | When to use |\n",
    "|--------|-----|--------|---------------|\n",
    "| **EDA** | Fast, offline | Less sophisticated | Baseline, large datasets |\n",
    "| **KNEO** | Good semantics | Requires embeddings | Noisy datasets |\n",
    "| **LLM** | High quality | Slow, requires GPU | Small datasets, max quality |\n",
    "\n",
    "### How to replicate experiments:\n",
    "\n",
    "1. Edit `configs/config.yaml` to change parameters\n",
    "2. Add your datasets in `data/`\n",
    "3. Run this notebook from the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ DEMO COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Edit configs/config.yaml for your experiments\")\n",
    "print(\"2. Add your datasets in data/\")\n",
    "print(\"3. Use scripts/run_baseline.py for full runs\")\n",
    "print(\"4. Use scripts/run_llm.py for LLM on large datasets\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
