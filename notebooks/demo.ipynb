{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b26e82",
   "metadata": {},
   "source": [
    "# Data Anonymization with LLMs - End-to-End Demo\n",
    "\n",
    "This notebook demonstrates the modular framework for text anonymization.\n",
    "\n",
    "**Available methods:**\n",
    "- **EDA** (Easy Data Augmentation): Baseline techniques using WordNet\n",
    "- **KNEO** (Knowledge-based Neighbor Operation): Embeddings (GloVe/fastText)\n",
    "- **LLM**: Language models via Ollama (gemma2, llama3.2, mistral, etc.)\n",
    "\n",
    "**To change configuration:**\n",
    "Edit the `configs/config.yaml` file to change models, datasets, and parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd8172",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d12c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (first time only)\n",
    "# !pip install -r ../requirements.txt\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167443f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "# Import framework modules\n",
    "from eda_anonymizer import EDAAnonymizer\n",
    "from kneo_anonymizer import KNEOAnonymizer\n",
    "from llm_anonymizer import OllamaAnonymizer, PROMPT_TEMPLATES\n",
    "from metrics import AnonymizationMetrics\n",
    "from utils import (\n",
    "    load_config, \n",
    "    load_all_datasets, \n",
    "    set_all_seeds,\n",
    "    create_output_dir,\n",
    "    save_anonymized_dataset,\n",
    "    save_metrics,\n",
    "    print_comparison_table\n",
    ")\n",
    "\n",
    "# Import visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup visualization\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc5369",
   "metadata": {},
   "source": [
    "from src.utils import load_config, load_all_datasets\n",
    "from src.eda_anonymizer import EDAAnonymizer\n",
    "from src.kneo_anonymizer import KNEOAnonymizer\n",
    "from src.llm_anonymizer import OllamaAnonymizer\n",
    "from src.metrics import AnonymizationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27199532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from YAML file\n",
    "config = load_config('../configs/config.yaml')\n",
    "\n",
    "# Display main configuration\n",
    "print(\"\\nCURRENT CONFIGURATION:\")\n",
    "print(f\"   EDA alphas: SR={config['eda']['alpha_sr']}, RI={config['eda']['alpha_ri']}, RS={config['eda']['alpha_rs']}, RD={config['eda']['alpha_rd']}\")\n",
    "print(f\"   KNEO: model={config['kneo']['embedding_model']}, k={config['kneo']['k']}\")\n",
    "print(f\"   LLM: model={config['llm']['model_name']}, temp={config['llm']['temperature']}\")\n",
    "print(f\"   Metrics: SBERT={config['metrics']['sbert_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b034c721",
   "metadata": {},
   "source": [
    "### 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample size for quick testing (None = full dataset)\n",
    "SAMPLE_SIZES = {\n",
    "    'train': 100,       # Change to None to use all data\n",
    "    'validation': 50,\n",
    "    'test': None\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "datasets = load_all_datasets(\n",
    "    config, \n",
    "    base_dir='../data',\n",
    "    sample_sizes=SAMPLE_SIZES\n",
    ")\n",
    "\n",
    "# Extract for convenience\n",
    "if 'train' in datasets:\n",
    "    train_texts, train_labels = datasets['train']\n",
    "    print(f\"\\nTraining set: {len(train_texts)} samples\")\n",
    "\n",
    "if 'validation' in datasets:\n",
    "    val_texts, val_labels = datasets['validation']\n",
    "    print(f\"Validation set: {len(val_texts)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31176ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some examples\n",
    "print(\"\\nExamples from dataset:\\n\")\n",
    "for i in range(min(5, len(val_texts))):\n",
    "    print(f\"[{val_labels[i]}] {val_texts[i][:100]}...\" if len(val_texts[i]) > 100 else f\"[{val_labels[i]}] {val_texts[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4148f4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Metodo 1: Easy Data Augmentation (EDA)\n",
    "\n",
    "EDA applica 4 tecniche di augmentation:\n",
    "- **SR** (Synonym Replacement): Sostituisce parole con sinonimi da WordNet\n",
    "- **RI** (Random Insertion): Inserisce sinonimi casuali\n",
    "- **RS** (Random Swap): Scambia posizioni di parole\n",
    "- **RD** (Random Deletion): Elimina parole casuali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EDA Anonymizer\n",
    "eda = EDAAnonymizer()\n",
    "\n",
    "# Apply anonymization\n",
    "print(\"Applying EDA...\")\n",
    "anonymized_eda = eda.anonymize_batch(\n",
    "    val_texts,\n",
    "    alpha_sr=config['eda']['alpha_sr'],\n",
    "    alpha_ri=config['eda']['alpha_ri'],\n",
    "    alpha_rs=config['eda']['alpha_rs'],\n",
    "    alpha_rd=config['eda']['alpha_rd'],\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "print(f\"\\nEDA completed: {len(anonymized_eda)} sentences anonymized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22deb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples\n",
    "print(\"EDA anonymization examples:\\n\")\n",
    "print(\"-\" * 80)\n",
    "for i in range(min(5, len(val_texts))):\n",
    "    print(f\"\\nORIGINAL:  {val_texts[i]}\")\n",
    "    print(f\"EDA:       {anonymized_eda[i]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5981cde5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Metodo 2: KNEO (Knowledge-based Neighbor Operation)\n",
    "\n",
    "KNEO usa embeddings pre-addestrati per sostituire parole con vicini semantici.\n",
    "\n",
    "**Modelli disponibili:**\n",
    "- `glove-wiki-gigaword-50/100/200/300` - GloVe embeddings\n",
    "- `fasttext-wiki-news-subwords-300` - FastText (migliore per testi rumorosi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KNEO Anonymizer\n",
    "kneo = KNEOAnonymizer(\n",
    "    embedding_model=config['kneo']['embedding_model'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply anonymization\n",
    "print(\"\\nApplying KNEO...\")\n",
    "anonymized_kneo = kneo.anonymize_batch(\n",
    "    val_texts,\n",
    "    k=config['kneo']['k'],\n",
    "    strategy=config['kneo']['strategy'],\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "print(f\"\\nKNEO completed: {len(anonymized_kneo)} sentences anonymized\")\n",
    "\n",
    "# Cache statistics\n",
    "cache_stats = kneo.get_cache_stats()\n",
    "print(f\"Cache: {cache_stats['cache_size']} unique words processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ff94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples\n",
    "print(\"üìù KNEO anonymization examples:\\n\")\n",
    "print(\"-\" * 80)\n",
    "for i in range(min(5, len(val_texts))):\n",
    "    print(f\"\\nORIGINAL:  {val_texts[i]}\")\n",
    "    print(f\"KNEO:      {anonymized_kneo[i]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac5ac5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Method 3: LLM with Ollama\n",
    "\n",
    "Use local LLM models via Ollama for more sophisticated anonymization.\n",
    "\n",
    "### Ollama Setup (if not already installed)\n",
    "\n",
    "```bash\n",
    "# Run the setup script\n",
    "bash scripts/setup_ollama.sh\n",
    "\n",
    "# Or manually:\n",
    "# macOS: brew install ollama\n",
    "# Linux: curl -fsSL https://ollama.ai/install.sh | sh\n",
    "\n",
    "# Start the server\n",
    "ollama serve\n",
    "\n",
    "# Download a model (in another terminal)\n",
    "ollama pull gemma2:2b    # Small and fast\n",
    "ollama pull llama3.2     # Meta's latest\n",
    "ollama pull mistral      # Good balance\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try connecting to Ollama\n",
    "try:\n",
    "    llm = OllamaAnonymizer(\n",
    "        model_name=config['llm']['model_name'],\n",
    "        base_url=config['llm']['base_url'],\n",
    "        temperature=config['llm']['temperature'],\n",
    "        max_tokens=config['llm']['max_tokens'],\n",
    "        prompt_style=\"paraphrase\",\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    OLLAMA_AVAILABLE = True\n",
    "    print(\"\\nOllama connected and ready!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    OLLAMA_AVAILABLE = False\n",
    "    print(f\"\\nOllama not available: {e}\")\n",
    "    print(\"   Skip this section if you don't have Ollama installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb72c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LLM (only if available)\n",
    "if OLLAMA_AVAILABLE:\n",
    "    # Use a smaller subset for LLM (it's slower)\n",
    "    llm_sample_size = min(20, len(val_texts))\n",
    "    llm_texts = val_texts[:llm_sample_size]\n",
    "    llm_labels = val_labels[:llm_sample_size]\n",
    "    \n",
    "    print(f\"\\nApplying LLM ({llm_sample_size} samples)...\")\n",
    "    \n",
    "    anonymized_llm = llm.anonymize_batch(\n",
    "        llm_texts,\n",
    "        labels=llm_labels,\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nLLM completed: {len(anonymized_llm)} sentences anonymized\")\n",
    "else:\n",
    "    anonymized_llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc51731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show LLM examples\n",
    "if anonymized_llm:\n",
    "    print(\"LLM anonymization examples:\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    for i in range(min(5, len(anonymized_llm))):\n",
    "        print(f\"\\nORIGINAL:  {llm_texts[i]}\")\n",
    "        print(f\"LLM:       {anonymized_llm[i]}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1bbe2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Evaluation with Metrics\n",
    "\n",
    "Evaluate results with 4 metrics:\n",
    "\n",
    "| Metric | Category | Goal |\n",
    "|---------|-----------|----------|\n",
    "| Levenshtein Ratio | Irreversibility | ‚Üì Lower = better |\n",
    "| Jaccard Similarity | Irreversibility | ‚Üì Lower = better |\n",
    "| Cosine Similarity | Semantic Utility | ‚Üë Higher = better |\n",
    "| NER Score | Anonymization | ‚Üë Higher = better |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics module\n",
    "metrics = AnonymizationMetrics(\n",
    "    sbert_model=config['metrics']['sbert_model'],\n",
    "    spacy_model=config['metrics']['spacy_model'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf483b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate EDA - calculate mean scores\n",
    "print(\"\\nEvaluating EDA...\")\n",
    "eda_results = metrics.evaluate_all(val_texts, anonymized_eda, show_progress=True)\n",
    "\n",
    "# Get individual scores for distribution visualization\n",
    "eda_scores = {\n",
    "    'levenshtein': metrics.calculate_levenshtein_ratio_list(val_texts, anonymized_eda),\n",
    "    'jaccard': metrics.calculate_jaccard_similarity_list(val_texts, anonymized_eda),\n",
    "    'cosine': metrics.calculate_cosine_similarity_list(val_texts, anonymized_eda, show_progress=False),\n",
    "    'ner': metrics.calculate_ner_score_list(val_texts, anonymized_eda)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate KNEO - calculate mean scores\n",
    "print(\"\\nEvaluating KNEO...\")\n",
    "kneo_results = metrics.evaluate_all(val_texts, anonymized_kneo, show_progress=True)\n",
    "\n",
    "# Get individual scores for distribution visualization\n",
    "kneo_scores = {\n",
    "    'levenshtein': metrics.calculate_levenshtein_ratio_list(val_texts, anonymized_kneo),\n",
    "    'jaccard': metrics.calculate_jaccard_similarity_list(val_texts, anonymized_kneo),\n",
    "    'cosine': metrics.calculate_cosine_similarity_list(val_texts, anonymized_kneo, show_progress=False),\n",
    "    'ner': metrics.calculate_ner_score_list(val_texts, anonymized_kneo)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LLM (if available)\n",
    "if anonymized_llm:\n",
    "    print(\"\\nEvaluating LLM...\")\n",
    "    llm_results = metrics.evaluate_all(llm_texts, anonymized_llm, show_progress=True)\n",
    "    \n",
    "    # Get individual scores for distribution visualization\n",
    "    llm_scores = {\n",
    "        'levenshtein': metrics.calculate_levenshtein_ratio_list(llm_texts, anonymized_llm),\n",
    "        'jaccard': metrics.calculate_jaccard_similarity_list(llm_texts, anonymized_llm),\n",
    "        'cosine': metrics.calculate_cosine_similarity_list(llm_texts, anonymized_llm, show_progress=False),\n",
    "        'ner': metrics.calculate_ner_score_list(llm_texts, anonymized_llm)\n",
    "    }\n",
    "else:\n",
    "    llm_results = None\n",
    "    llm_scores = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36017b5",
   "metadata": {},
   "source": [
    "### 5.1 Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "all_results = {\n",
    "    'EDA': eda_results,\n",
    "    'KNEO': kneo_results\n",
    "}\n",
    "\n",
    "if llm_results:\n",
    "    all_results['LLM'] = llm_results\n",
    "\n",
    "# Print comparison table\n",
    "print_comparison_table(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a830721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for analysis\n",
    "df_results = pd.DataFrame(all_results).T\n",
    "df_results.index.name = 'Method'\n",
    "df_results = df_results.round(4)\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9da938",
   "metadata": {},
   "source": [
    "### 5.2 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9389909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart for comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics_names = ['levenshtein_ratio', 'jaccard_similarity', 'cosine_similarity', 'ner_score']\n",
    "metric_labels = ['Levenshtein Ratio ‚Üì', 'Jaccard Similarity ‚Üì', 'Cosine Similarity ‚Üë', 'NER Score ‚Üë']\n",
    "colors = ['#e74c3c', '#e74c3c', '#27ae60', '#27ae60']\n",
    "\n",
    "methods = list(all_results.keys())\n",
    "\n",
    "for idx, (metric, label, color) in enumerate(zip(metrics_names, metric_labels, colors)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    values = [all_results[m][metric] for m in methods]\n",
    "    \n",
    "    bars = ax.bar(methods, values, color=color, alpha=0.8, edgecolor='black')\n",
    "    ax.set_title(label, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    for bar, val in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.suptitle('Anonymization Metrics Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f0f91",
   "metadata": {},
   "source": [
    "### 5.3 Distribution Visualizations\n",
    "\n",
    "Visualize the distribution of scores for each metric across different methods using ridge plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6930b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for distribution plots\n",
    "# Combine all methods' scores into dictionaries for each metric\n",
    "\n",
    "# Levenshtein Ratio Distributions\n",
    "lev_distributions = {\n",
    "    'EDA': eda_scores['levenshtein'],\n",
    "    'KNEO': kneo_scores['levenshtein']\n",
    "}\n",
    "\n",
    "# Jaccard Similarity Distributions\n",
    "jac_distributions = {\n",
    "    'EDA': eda_scores['jaccard'],\n",
    "    'KNEO': kneo_scores['jaccard']\n",
    "}\n",
    "\n",
    "# Cosine Similarity Distributions\n",
    "cos_distributions = {\n",
    "    'EDA': eda_scores['cosine'],\n",
    "    'KNEO': kneo_scores['cosine']\n",
    "}\n",
    "\n",
    "# NER Score Distributions\n",
    "ner_distributions = {\n",
    "    'EDA': eda_scores['ner'],\n",
    "    'KNEO': kneo_scores['ner']\n",
    "}\n",
    "\n",
    "# Add LLM if available\n",
    "if llm_scores:\n",
    "    lev_distributions['LLM'] = llm_scores['levenshtein']\n",
    "    jac_distributions['LLM'] = llm_scores['jaccard']\n",
    "    cos_distributions['LLM'] = llm_scores['cosine']\n",
    "    ner_distributions['LLM'] = llm_scores['ner']\n",
    "\n",
    "print(\"Distribution data prepared for plotting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a33fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Levenshtein Ratio Distribution (Ridge Plot)\n",
    "print(\"\\nLevenshtein Ratio Distribution (‚Üì lower is better)\")\n",
    "metrics.plot_metric_distributions(\n",
    "    lev_distributions,\n",
    "    metric_name=\"Levenshtein Ratio\",\n",
    "    plot_type=\"ridge\",\n",
    "    color_palette=\"Reds_r\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08c739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Jaccard Similarity Distribution (Ridge Plot)\n",
    "print(\"\\nJaccard Similarity Distribution (‚Üì lower is better)\")\n",
    "metrics.plot_metric_distributions(\n",
    "    jac_distributions,\n",
    "    metric_name=\"Jaccard Similarity\",\n",
    "    plot_type=\"ridge\",\n",
    "    color_palette=\"Oranges_r\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Cosine Similarity Distribution (Ridge Plot)\n",
    "print(\"\\nCosine Similarity Distribution (‚Üë higher is better)\")\n",
    "metrics.plot_metric_distributions(\n",
    "    cos_distributions,\n",
    "    metric_name=\"Cosine Similarity (Semantic Utility)\",\n",
    "    plot_type=\"ridge\",\n",
    "    color_palette=\"Greens\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cc421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NER Score Distribution (Ridge Plot)\n",
    "print(\"\\nNER Score Distribution (‚Üë higher is better)\")\n",
    "metrics.plot_metric_distributions(\n",
    "    ner_distributions,\n",
    "    metric_name=\"NER Score (Anonymization Quality)\",\n",
    "    plot_type=\"ridge\",\n",
    "    color_palette=\"Blues\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337bfb1",
   "metadata": {},
   "source": [
    "#### Alternative: Overlay Histograms\n",
    "\n",
    "You can also use overlapping histograms instead of ridge plots by changing `plot_type=\"overlay\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Overlay plot for Cosine Similarity (uncomment to use)\n",
    "# metrics.plot_metric_distributions(\n",
    "#     cos_distributions,\n",
    "#     metric_name=\"Cosine Similarity\",\n",
    "#     plot_type=\"overlay\",\n",
    "#     color_palette=\"Set2\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1cc662",
   "metadata": {},
   "source": [
    "### 5.4 Paraphrase Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c733d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Paraphrase Retrieval for EDA\n",
    "print(\"\\nEvaluating Paraphrase Retrieval for EDA...\")\n",
    "eda_retrieval = metrics.evaluate_paraphrase_retrieval(\n",
    "    original_sentences=val_texts,\n",
    "    paraphrased_sentences=anonymized_eda,\n",
    "    k_values=[1, 5, 10],\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Paraphrase Retrieval for KNEO\n",
    "print(\"\\nEvaluating Paraphrase Retrieval for KNEO...\")\n",
    "kneo_retrieval = metrics.evaluate_paraphrase_retrieval(\n",
    "    original_sentences=val_texts,\n",
    "    paraphrased_sentences=anonymized_kneo,\n",
    "    k_values=[1, 5, 10],\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b93d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Paraphrase Retrieval for LLM (if available)\n",
    "if anonymized_llm:\n",
    "    print(\"\\nEvaluating Paraphrase Retrieval for LLM...\")\n",
    "    llm_retrieval = metrics.evaluate_paraphrase_retrieval(\n",
    "        original_sentences=llm_texts,\n",
    "        paraphrased_sentences=anonymized_llm,\n",
    "        k_values=[1, 5, 10],\n",
    "        show_progress=True\n",
    "    )\n",
    "else:\n",
    "    llm_retrieval = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1917478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Paraphrase Retrieval Results\n",
    "retrieval_results = {\n",
    "    'EDA': eda_retrieval,\n",
    "    'KNEO': kneo_retrieval\n",
    "}\n",
    "\n",
    "if llm_retrieval:\n",
    "    retrieval_results['LLM'] = llm_retrieval\n",
    "\n",
    "# Create DataFrame for comparison\n",
    "df_retrieval = pd.DataFrame(retrieval_results).T\n",
    "df_retrieval.index.name = 'Method'\n",
    "df_retrieval = df_retrieval.round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PARAPHRASE RETRIEVAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(\"Lower accuracy = Better privacy protection\")\n",
    "print(\"=\"*60)\n",
    "display(df_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a60c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Paraphrase Retrieval Results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "methods = list(retrieval_results.keys())\n",
    "k_values = [1, 5, 10]\n",
    "x = np.arange(len(methods))\n",
    "width = 0.25\n",
    "\n",
    "for i, k in enumerate(k_values):\n",
    "    values = [retrieval_results[m][f'Accuracy@{k}'] for m in methods]\n",
    "    bars = ax.bar(x + i*width, values, width, label=f'Accuracy@{k}', alpha=0.8)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, height + 1,\n",
    "                f'{val:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Method', fontsize=12)\n",
    "ax.set_ylabel('Retrieval Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Paraphrase Retrieval Attack Results\\n(Lower is Better for Privacy)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Lower retrieval accuracy means better privacy protection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ca29f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = create_output_dir(config)\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87358c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save anonymized datasets\n",
    "if config['output']['save_anonymized']:\n",
    "    save_anonymized_dataset(anonymized_eda, val_labels, output_dir, 'eda')\n",
    "    save_anonymized_dataset(anonymized_kneo, val_labels, output_dir, 'kneo')\n",
    "    \n",
    "    if anonymized_llm:\n",
    "        save_anonymized_dataset(anonymized_llm, llm_labels, output_dir, 'llm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abdad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "if config['output']['save_metrics']:\n",
    "    save_metrics(all_results, output_dir, 'comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593e0fd2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Conclusions\n",
    "\n",
    "### Summary of methods:\n",
    "\n",
    "| Method | Pros | Cons | When to use |\n",
    "|--------|-----|--------|---------------|\n",
    "| **EDA** | Fast, offline | Less sophisticated | Baseline, large datasets |\n",
    "| **KNEO** | Good semantics | Requires embeddings | Noisy datasets |\n",
    "| **LLM** | High quality | Slow, requires GPU | Small datasets, max quality |\n",
    "\n",
    "### New Visualization Features:\n",
    "\n",
    "This notebook now includes **distribution visualizations** for all metrics:\n",
    "- **Ridge Plots**: Show score distributions for each method (stacked density plots)\n",
    "- **Paraphrase Retrieval**: Privacy attack simulation to measure re-identification risk\n",
    "- Lower retrieval accuracy = Better privacy protection\n",
    "\n",
    "### How to replicate experiments:\n",
    "\n",
    "1. Edit `configs/config.yaml` to change parameters\n",
    "2. Add your datasets in `data/`\n",
    "3. Run this notebook from the beginning\n",
    "4. Compare methods using both mean scores and distribution visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEMO COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Edit configs/config.yaml for your experiments\")\n",
    "print(\"2. Add your datasets in data/\")\n",
    "print(\"3. Use scripts/run_baseline.py for full runs\")\n",
    "print(\"4. Use scripts/run_llm.py for LLM on large datasets\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
